{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21566,"status":"ok","timestamp":1702608455073,"user":{"displayName":"류세종","userId":"00154637030721439871"},"user_tz":-540},"id":"yAKXA7Z7Gwz0","outputId":"b449ef5a-b88d-457d-e1d7-85c4680acd28"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# connect google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"4IAMDrBMnClu"},"source":["# Import library"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"lrjtVs-oGODv","executionInfo":{"status":"ok","timestamp":1702608458971,"user_tz":-540,"elapsed":691,"user":{"displayName":"류세종","userId":"00154637030721439871"}}},"outputs":[],"source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"markdown","metadata":{"id":"UHVW6Ht3nE_L"},"source":["# Part1: goodFeaturesToTrack\n","- Fill the missing part (denoted as ```fill here```) of the code\n","- We provide procedure comments for complete the function"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"AEPUBxp_GPpl","executionInfo":{"status":"ok","timestamp":1702608465082,"user_tz":-540,"elapsed":2,"user":{"displayName":"류세종","userId":"00154637030721439871"}}},"outputs":[],"source":["def goodFeaturesToTrack(image, maxCorners=100, qualityLevel=0.03, blocksize=7):\n","\n","    # Image bluring wih averaging filter\n","    # Only cv2.filter2D is allowed for convolution operation!\n","    '''fill here'''\n","    avg_filter = (1/(blocksize**2))*np.ones((blocksize, blocksize))\n","    #avg_filter = (1/49)*np.ones((7, 7))\n","    image = cv2.filter2D(image, -1, avg_filter)\n","\n","    # Compute gradients\n","    '''fill here'''\n","    sobel_x = np.array([[-1/8, 0, 1/8], [-2/8, 0, 2/8], [-1/8, 0, 1/8]])\n","    sobel_y = np.array([[-1/8, -2/8, -1/8], [0, 0, 0], [1/8, 2/8, 1/8]])\n","    #prewitt_x = np.array([[-1/6, 0, 1/6], [-1/6, 0, 1/6], [-1/6, 0, 1/6]])\n","    #prewitt_y = np.array([[-1/6, -1/6, -1/6], [0, 0, 0], [1/6, 1/6, 1/6]])\n","    Ix = cv2.filter2D(image, -1, sobel_x)\n","    Iy = cv2.filter2D(image, -1, sobel_y)\n","\n","    # Compute products of gradients at each pixel\n","    '''fill here'''\n","    Ixx = Ix * Ix\n","    Iyy = Iy * Iy\n","    Ixy = Ix * Iy\n","\n","    # Compute the sums of products of gradients in local windows\n","    '''fill here'''\n","    offset = int(np.floor(blocksize/2))\n","    Sxx = np.zeros(image.shape)\n","    Syy = np.zeros(image.shape)\n","    Sxy = np.zeros(image.shape)\n","    for row in range(offset, image.shape[0]-offset):\n","        for col in range(offset, image.shape[1]-offset):\n","            Sxx[row, col] = np.sum(Ixx[row-offset:row+offset+1, col-offset:col+offset+1])\n","            Syy[row, col] = np.sum(Iyy[row-offset:row+offset+1, col-offset:col+offset+1])\n","            Sxy[row, col] = np.sum(Ixy[row-offset:row+offset+1, col-offset:col+offset+1])\n","\n","\n","    # Compute the determinant and trace of the matrix M for each pixel\n","    '''fill here'''\n","    detM = (Sxx*Syy) - (Sxy**2)\n","    traceM = Sxx + Syy\n","\n","    # Compute the Harris response with detM and traceM\n","    '''fill here'''\n","    #harris_response = detM - 0.04 * (traceM ** 2)\n","    harris_response = detM / (traceM + 1e-5)\n","\n","    # Threshold the Harris response to find candidate corners\n","    '''fill here'''\n","    #corners = np.argwhere(harris_response > qualityLevel * np.max(harris_response))\n","    corners = np.argwhere(harris_response > qualityLevel)\n","\n","    # Sort the corners by Harris response in descending order\n","    sorted_corners = corners[np.argsort(harris_response[corners[:, 0], corners[:, 1]])[::-1]]\n","\n","    # Keep the top 'maxCorners' corners\n","    selected_corners = sorted_corners[:maxCorners]\n","\n","    final_corners = np.array(selected_corners)\n","    final_corners = final_corners.reshape(-1, 1, 2)\n","\n","    return final_corners"]},{"cell_type":"markdown","metadata":{"id":"0gcb42xzntML"},"source":["# Part2: Optical flow with Lukas-Kanade\n","- Fill the missing part (denoted as ```fill here```) of the code\n","- We provide procedure comments for complete the function"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"lv7zvb_nG8ql","executionInfo":{"status":"ok","timestamp":1702608469063,"user_tz":-540,"elapsed":507,"user":{"displayName":"류세종","userId":"00154637030721439871"}}},"outputs":[],"source":["\n","def optical_flow(old_frame, new_frame, window_size, min_quality):\n","\n","    feature_list = goodFeaturesToTrack(old_frame, max_corners, min_quality, blocksize)\n","\n","    w = int(window_size/2)\n","\n","    # Normalize\n","    old_frame = old_frame / 255\n","    new_frame = new_frame / 255\n","\n","    # Convolve to get gradients w.r.to X, Y and T dimensions\n","    '''fill here'''\n","    kernel_x = np.array([[-1/8, 0, 1/8], [-2/8, 0, 2/8], [-1/8, 0, 1/8]])\n","    kernel_y = np.array([[-1/8, -2/8, -1/8], [0, 0, 0], [1/8, 2/8, 1/8]])\n","    kernel_t = np.array([[1/9, 1/9, 1/9], [1/9, 1/9, 1/9], [1/9, 1/9, 1/9]])\n","\n","    # cv2.filter2D is allowed for convolution!\n","    '''fill here'''\n","    fx =  cv2.filter2D(old_frame, -1, kernel_x)\n","    fy =  cv2.filter2D(old_frame, -1, kernel_y)\n","    ft =  cv2.filter2D(new_frame, -1, kernel_t) - cv2.filter2D(old_frame, -1, -kernel_t)\n","\n","    u = np.zeros(old_frame.shape)\n","    v = np.zeros(old_frame.shape)\n","\n","    for feature in feature_list:  # for every corner\n","        i, j = feature.ravel()  # get cordinates of the corners (i,j).\n","        i, j = int(i), int(j)  # i,j are floats initially so convert to integer type\n","\n","        '''fill here'''\n","        I_x = fx[i-w:i+w+1, j-w:j+w+1].flatten()\n","        I_y = fy[i-w:i+w+1, j-w:j+w+1].flatten()\n","        I_t = ft[i-w:i+w+1, j-w:j+w+1].flatten()\n","\n","        b = np.reshape(I_t, (I_t.shape[0], 1))\n","        A = np.vstack((I_x, I_y)).T\n","\n","        '''fill here'''\n","        U = np.matmul(np.linalg.pinv(np.matmul(A.T, A)), np.matmul(A.T, b))  # Solving for (u,v) i.e., U\n","\n","        u[i, j] = U[0][0]\n","        v[i, j] = U[1][0]\n","\n","    return (u, v)\n"]},{"cell_type":"markdown","metadata":{"id":"x4N4xHKEHAjA"},"source":["# Main function\n","- If part1 and part2 were filled properly, the 'output.avi' will be generated!\n","- For google colab, as cv2.imshow() is not provided, so please use cv2_imshow (google.colab.patches) instead  "]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1f4jSslIL4_rgbBkqzz_2mqh392p1u87Z"},"id":"APQHNcblG_Jp","outputId":"edb7075b-b931-4a20-e940-1e9ce8ee1635","executionInfo":{"status":"ok","timestamp":1702612933025,"user_tz":-540,"elapsed":530872,"user":{"displayName":"류세종","userId":"00154637030721439871"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["cap = cv2.VideoCapture('/content/drive/MyDrive/Colab Notebooks/Computer Vision/slow/slow.mp4')\n","\n","# Take first frame and find corners in it\n","ret, old_frame = cap.read()\n","\n","# Width and height of the file to save\n","width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n","height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n","\n","# 'output.mp4' will be generated!\n","fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n","out = cv2.VideoWriter('output.mp4',  fourcc, 30.0, (int(width), int(height)))\n","\n","old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n","\n","### old_frame => old_gray\n","# Shi Tomasi parameter\n","max_corners = 100\n","min_quality = 0.3\n","blocksize = 7\n","p0 = goodFeaturesToTrack(old_gray, max_corners, min_quality, blocksize)\n","\n","# Create a mask image for drawing purposes\n","mask = np.zeros_like(old_frame)\n","\n","while(1):\n","    ret, current_frame = cap.read()\n","    if not ret:\n","        break\n","    frame_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)\n","\n","    # calculate optical flow\n","    U, V = optical_flow(old_gray, frame_gray, 15, 0.03)\n","\n","    for i in range(current_frame.shape[0]):\n","        for j in range(current_frame.shape[1]):\n","            u, v = U[i][j], V[i][j]\n","            if u and v:\n","                mask = cv2.line(mask, (j, i), (int(round(j + u)), int(round(i + v))), (0, 255, 0), 2)\n","                frame = cv2.arrowedLine(current_frame, (j, i), (int(round(j + u)), int(round(i + v))), (0, 255, 0), thickness=2)\n","                current_frame = cv2.add(current_frame, mask)\n","\n","    # Display the frame with optical flow vectors\n","    cv2_imshow(current_frame)\n","    out.write(current_frame)\n","    # Break the loop if 'Esc' key is pressed\n","    if cv2.waitKey(30) == 27:\n","        break\n","\n","    # Set the current frame as the previous frame for the next iteration\n","    old_gray = frame_gray\n","\n","# Release the video capture object\n","cap.release()\n","out.release()\n","\n","# Close the plot window when done\n","plt.close()\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OTF_2ulyHPJF"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}